{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.stats import skew,boxcox\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def remove_skewness(data) :\n",
    "    columns = data.columns\n",
    "\n",
    "    # removing the skewness from the data set\n",
    "    skew_threshold = 0.5\n",
    "\n",
    "    for col in columns : \n",
    "        skewness_before = skew(data[col])\n",
    "\n",
    "        if abs(skewness_before) > skew_threshold:\n",
    "            # Apply Box-Cox transformation and find the best lambda\n",
    "            min_value = data[col].min()\n",
    "            if (min_value<=0):\n",
    "                data[col] += (-min_value+1)\n",
    "            transformed_data, lambda_best_fit = boxcox(data[col])  # Adding 1 to avoid zero values\n",
    "            data[col] = transformed_data  # Replace the original feature with the transformed data\n",
    "        \n",
    "        skewness_after = skew(data[col])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def oneHotEncoding(data):\n",
    "    # performing one hot encoding on discrete features\n",
    "    discrete_features = ['cp_dose','cp_time','cp_type']\n",
    "    data = pd.get_dummies(data,columns=discrete_features,dtype=int)\n",
    "    return data \n",
    "\n",
    "def remove_outliers(data,Y):\n",
    "    s = set()\n",
    "    columns = data.columns\n",
    "\n",
    "    for col in columns:\n",
    "        Q1 = data[col].quantile(0.25)\n",
    "        Q3 = data[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Define lower and upper bounds for outliers\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        for index, row in data.iterrows():\n",
    "            if index in s:\n",
    "                continue\n",
    "            if (row[col]<lower_bound or row[col]>upper_bound):\n",
    "                data = data.drop(index,axis=0)\n",
    "                \n",
    "                Y = Y.drop(index,axis=0)\n",
    "                \n",
    "                s.add(index)\n",
    "    data = data.reset_index(drop = True)\n",
    "    Y = Y.reset_index(drop = True)\n",
    "    data = pd.DataFrame(data)\n",
    "    Y = pd.DataFrame(Y)\n",
    "    return data, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KFold Progress:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 902us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KFold Progress:  33%|███▎      | 1/3 [00:03<00:07,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 786us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KFold Progress:  67%|██████▋   | 2/3 [00:06<00:03,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 758us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KFold Progress: 100%|██████████| 3/3 [00:10<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.015783455\n",
      "Average Validation Loss: 0.018885834\n",
      "==================================================\n",
      "PCA: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KFold Progress:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KFold Progress:  33%|███▎      | 1/3 [00:03<00:06,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 684us/step\n",
      "105/105 [==============================] - 0s 746us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KFold Progress:  67%|██████▋   | 2/3 [00:06<00:03,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 783us/step\n",
      "105/105 [==============================] - 0s 708us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KFold Progress: 100%|██████████| 3/3 [00:09<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.014804944\n",
      "Average Validation Loss: 0.018747715\n",
      "==================================================\n",
      "PCA: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KFold Progress:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KFold Progress:  33%|███▎      | 1/3 [00:03<00:07,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 816us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KFold Progress:  67%|██████▋   | 2/3 [00:06<00:03,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 794us/step\n",
      "105/105 [==============================] - 0s 910us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KFold Progress: 100%|██████████| 3/3 [00:10<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.0136337085\n",
      "Average Validation Loss: 0.018468352\n",
      "==================================================\n",
      "PCA: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KFold Progress:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 959us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KFold Progress:  33%|███▎      | 1/3 [00:04<00:08,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 936us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KFold Progress:  67%|██████▋   | 2/3 [00:08<00:04,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KFold Progress: 100%|██████████| 3/3 [00:14<00:00,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.011711046\n",
      "Average Validation Loss: 0.018377213\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load data\n",
    "train_features = pd.read_csv('train_features.csv')\n",
    "train_targets = pd.read_csv('train_targets_scored.csv')\n",
    "train_features = train_features.drop('sig_id', axis=1)\n",
    "train_targets = train_targets.drop('sig_id', axis=1)\n",
    "\n",
    "train_features, test_features, train_scored, test_scored = train_test_split(\n",
    "    train_features, train_targets, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_features = train_features.reset_index(drop=True)\n",
    "train_targets = train_targets.reset_index(drop=True)\n",
    "train_scored = train_scored.reset_index(drop=True)\n",
    "test_scored = test_scored.reset_index(drop=True)\n",
    "\n",
    "train_features = train_features[:5000]\n",
    "test_features = test_features[:5000]\n",
    "train_scored = train_scored[:5000]\n",
    "test_scored = test_scored[:5000]\n",
    "\n",
    "# Preprocess data\n",
    "# train_features = remove_skewness(train_features)\n",
    "train_features = oneHotEncoding(train_features)\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "kfold = 3\n",
    "kf = KFold(n_splits=kfold, shuffle=True, random_state=42)\n",
    "\n",
    "# Neural Network parameters\n",
    "input_dim = train_features.shape[1]\n",
    "output_dim = train_scored.shape[1]\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# List of PCA values\n",
    "pca_values = [50, 100, 200, 500]\n",
    "\n",
    "for pca_value in pca_values:\n",
    "    print(f\"PCA: {pca_value}\")\n",
    "    avg_training = []\n",
    "    avg_validation = []\n",
    "\n",
    "    for train_index, test_index in tqdm(kf.split(train_features), total=kfold, desc=\"KFold Progress\"):\n",
    "        cross_val_scores = []\n",
    "        train_cross_val_score = []\n",
    "\n",
    "        X_train, X_test = train_features[train_index], train_features[test_index]\n",
    "        y_train, y_test = train_scored.iloc[train_index].values, train_scored.iloc[test_index].values\n",
    "\n",
    "        # Apply PCA\n",
    "        pca = PCA(n_components=pca_value)\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "\n",
    "        # Build the neural network model\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(pca_value,)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(output_dim, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "\n",
    "        # Calculate cross-entropy loss\n",
    "        loss = np.mean(tf.keras.losses.binary_crossentropy(y_test, y_pred))\n",
    "        loss_train = np.mean(tf.keras.losses.binary_crossentropy(y_train, y_train_pred))\n",
    "\n",
    "        cross_val_scores.append(loss)\n",
    "        train_cross_val_score.append(loss_train)\n",
    "\n",
    "        avg_training.append(np.mean(train_cross_val_score))\n",
    "        avg_validation.append(np.mean(cross_val_scores))\n",
    "\n",
    "    # Print or use the average training and validation scores as needed\n",
    "    print(\"Average Training Loss:\", np.mean(avg_training))\n",
    "    print(\"Average Validation Loss:\", np.mean(avg_validation))\n",
    "    print(\"=\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
